Анализ записей журнала

Чтобы проанализировать зафиксированные в журналах действия, необходимо их обработать. В данной работе будут рассмотрены методы обработки данных утилитами linux, для разбора основных принципов анализа журналов. В дальнейших работах будут использованы более элегантные и эффективные методы.

Используемые утилиты linux:
```
- grep, egrep, fgrep, pgrep
- head, tail
- cut, tr
- sort, uniq, join
- sed
- awk
```

### Пример 1. Количество уникальных ip-адресов в журнале

Такая информация может быть полезна для примерной оценки трафика или выявления аномалий.
Для начала строку журнала необходимо разделить по столбцам.
Пример ниже с помощью утилиты `cut` позволит вывести только ip-адреса, которые обращались к веб-серверу:

```bash
sudo cat /var/log/nginx/access.log | cut -d' ' -f1
# cut - это утилита, которая может делить строку на части по разделителям
# параметр -d определяет разделитель (в данном случае - пробел)
# параметр -f определяет какие столбцы нужно вывести в результат
```

<aside>
<img src="/icons/light-bulb_gray.svg" alt="/icons/light-bulb_gray.svg" width="40px" /> Если вывод команд слишком большой, то можно применить `| head` в конце команды для вывода первых 10 строк результата
</aside>

С помощью утилиты sort можно отсортировать адреса
С помощью утилиты uniq можно вывести только уникальные адреса и количество их встречаемости в журнале

```bash
sudo cat ~/access.log | cut -d' ' -f1 | sort | uniq -c
# параметр -c в команде uniq позволяет вывести количество дубликатов значения

sudo cat ~/access.log | cut -d' ' -f1 | sort | uniq -c | sort -k1 -rn
# еще раз отсортируем - в этот раз по количеству
# параметр -k указывает по какому столбцу сортировать
# параметр -r указывает на обратную сортировку
# параметр -n указывает на численную сортировку вместо строковой (1, 2, 100 вместо 1, 100, 2)
# первая команда sort нужна, так как uniq считает только подряд идущие дубликаты, а вторая, чтобы найти наиболее встречаемые адреса
```

### Пример 2. Объем данных, запрошенных разными адресами

Поставим следующую задачу - найти выбросы в объеме запрашиваемых данных. Для этого нужно просуммировать 10-й столбец журнала - количество переданных байт для каждого ip-адреса  (в разных журналах распределение может быть разное по столбцам).
Для данной задачи необходимо подготовить небольшой bash-скрипт:

```bash
sudo awk ' {cnt[$1]+=$10} END { for (var in cnt) printf "%-15s %8d\n", var,  cnt[var];}' ~/access.log | sort -k 2 -rn
# cnt[$1]+=$10 - создаем ассоциированный массив cnt, где адрес - ключ, а количество байт суммируется со значением
# END - часть awk скрипта, выполняемая один раз в конце
# printf - вывод как просто print, но с применением форматирования вывода
# printf "%-15s %8d\n", ip, cnt[var]; вывод адреса (дополненного паддингом справа до 15 символов) и количества байт (дополненных паддингом слева до 8 символов)
```

Чтобы чуть добавить стиля можно использовать ascii графику для вывода гистограммы на основании полученных выше данных с помощью скрипта ниже:

```bash
function pr_bar ()
{
    local -i i raw maxraw scaled
    raw=$1
    maxraw=$2
    ((scaled=(MAXBAR*raw)/maxraw))
    # min size guarantee
    ((raw > 0 && scaled == 0)) && scaled=1    

    for((i=0; i<scaled; i++)) ; do printf '#' ; done
    printf '\n'

}

declare -A RA
declare -i MAXBAR max
max=0
MAXBAR=50
while read labl val
do
    let RA[$labl]=$val
    (( val > max )) && max=$val
done

for labl in "${!RA[@]}"
do
    printf '%-20.20s  ' "$labl"
    pr_bar ${RA[$labl]} $max
done
​```

```bash
awk '{cnt[$1]+=$10} END { for (var in cnt) print var, " ",  cnt[var];}' ~/access.log | sort -k 2 -rn | sort -k 2.1 -rn | bash histogram.sh
# histogram.sh - название нового скрипта
```

### Пример 3. Анализ запросов, пришедших с одного определенного адреса

 Представим, что в процессе анализа статистики запросов от ip-адресов мы обнаруживаем аномально активный адрес (в данном случае 127.0.0.1). Необходимо разобраться в том, какие запросы отправляет данный адрес. Для решения поставленной задачи необходимо отфильтровать строки, содержащие адрес 127.0.0.1 и вывести 7-й столбец записи журнала (см распределение столбцов)

```bash
sudo cat ~/access.log | awk '$1 == "127.0.0.1" {print $7}'
# awk - сценарный язык построчного разбора и обработки входного потока по заданным шаблонам. В данной работе будет использован только малый объем его синтаксиса
# первая часть сценария awk ($1 == "127.0.0.1") определяет фильтрацию по 1 столбцу (awk по умолчанию делит по пробелам)
# вторая часть сценария awk ({print $7}) определяет вывод 7 столбца (можно использовать $0 для вывода полной строки)

# p.s. вывод команды очень большой - вспомните заметку об утилите head
```

Отсортируем журналы не просто от одного адреса, но так, чтобы timestamp соответствовал заданному времени.

```bash
sudo cat ~/access.log | awk '$1 == "127.0.0.1" && $4 ~ "23/Sep/2023:12" {print $7}'
#подправить дату под временные метки своего ноутбука
```
